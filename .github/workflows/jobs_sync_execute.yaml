on:
  workflow_call:
    inputs:
      # pass in environment through manual trigger, if not passed in, default to 'dev'
      PROJECT_ID:
        required: true
        type: string
      GITHUB_NAME:
        required: true
        type: string
jobs:
  changed-files:
    runs-on: ubuntu-latest
    outputs:
      matrixDataflow: ${{ steps.set-matrix-dataflow.outputs.matrix }}
      changedDataflow: ${{ steps.changed-files-dataflow.outputs.all_changed_files }}
      matrixSpark: ${{ steps.set-matrix-spark.outputs.matrix }}
      changedSpark: ${{ steps.changed-files-spark.outputs.all_changed_files }}
    permissions:
      contents: "write"
      pull-requests: "write"
      id-token: "write"
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          fetch-depth: 0 # needed for tj-actions/changed-files
      # Dataflow
      - name: Get changed files dataflow
        id: changed-files-dataflow
        uses: tj-actions/changed-files@v32
        with:
          json: true
          files: |
            /stacks/**/src/dataflows/**/*.py
      - id: set-matrix-dataflow
        run: echo "matrix={\"container\":${{ steps.changed-files-dataflow.outputs.all_changed_files }}}" >> "$GITHUB_OUTPUT"
      # Spark
      - name: Get changed files spark
        id: changed-files-spark
        uses: tj-actions/changed-files@v32
        with:
          json: true
          files: |
            /stacks/**/src/spark/**/*.py
      - id: set-matrix-spark
        run: echo "matrix={\"container\":${{ steps.changed-files-spark.outputs.all_changed_files }}}" >> "$GITHUB_OUTPUT"

  matrix-job-dataflow:
    name: Sync Dataflow
    if: ${{ needs.changed-files.outputs.changedDataflow != '[]' }}
    runs-on: ubuntu-latest
    permissions:
      contents: "write"
      pull-requests: "write"
      id-token: "write"
    needs: [changed-files]
    strategy:
      matrix: ${{ fromJSON(needs.changed-files.outputs.matrixDataflow) }}
      max-parallel: 4
      fail-fast: false
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - name: Test
        run: |
          ls -la
          echo ${{ matrix.container }}
      - name: Authenticate to Google using WIF
        id: auth
        uses: google-github-actions/auth@v0
        with:
          workload_identity_provider: ${{ secrets.CDO_WORKLOAD_IDENTITY_PROVIDER_GCP }}
          service_account: "cicd-sa@${{ inputs.PROJECT_ID }}.iam.gserviceaccount.com"
          project_id: ${{ inputs.PROJECT_ID }}
          token_format: "access_token"
      - uses: google-github-actions/setup-gcloud@v0
        with:
          project_id: ${{ inputs.PROJECT_ID }}
          export_default_credentials: true
      - name: "sync"
        run: |
          hash=$(echo -n ${PROJECT_ID} | sha256sum | cut -c1-4)
          echo $hash
          echo ${{ matrix.container }}
          export DIR="$(dirname "${{ matrix.container }}")"
          echo "DIR ${DIR}"
          gsutil -m rsync -r -c ./${DIR} gs://dataflow-scripts-${hash}/${DIR}

  matrix-job-spark:
    name: Sync Spark
    if: ${{ needs.changed-files.outputs.changedSpark != '[]' }}
    runs-on: ubuntu-latest
    permissions:
      contents: "write"
      pull-requests: "write"
      id-token: "write"
    needs: [changed-files]
    strategy:
      matrix: ${{ fromJSON(needs.changed-files.outputs.matrixSpark) }}
      max-parallel: 4
      fail-fast: false
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - name: Test
        run: |
          ls -la
          echo ${{ matrix.container }}
      - name: Authenticate to Google using WIF
        id: auth
        uses: google-github-actions/auth@v0
        with:
          workload_identity_provider: ${{ secrets.CDO_WORKLOAD_IDENTITY_PROVIDER_GCP }}
          service_account: "cicd-sa@${{ inputs.PROJECT_ID }}.iam.gserviceaccount.com"
          project_id: ${{ inputs.PROJECT_ID }}
          token_format: "access_token"
      - uses: google-github-actions/setup-gcloud@v0
        with:
          project_id: ${{ inputs.PROJECT_ID }}
          export_default_credentials: true
      - name: "sync"
        run: |
          hash=$(echo -n ${PROJECT_ID} | sha256sum | cut -c1-4)
          echo $hash
          echo ${{ matrix.container }}
          export DIR="$(dirname "${{ matrix.container }}")"
          echo "DIR ${DIR}"
          gsutil -m rsync -r -c ./${DIR} gs://spark-scripts-${hash}/${DIR}